import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="ConvexOpt | Fitness Intelligence",
    page_icon="üèãÔ∏è‚Äç‚ôÇÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour un design futuriste
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&family=Inter:wght@300;400;500;600;700&display=swap');
    
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }
    
    .main-title {
        font-family: 'Orbitron', monospace;
        font-size: 3.5rem;
        font-weight: 900;
        color: white;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        margin-bottom: 0.5rem;
        background: linear-gradient(45deg, #ffffff, #e0e0e0);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .subtitle {
        font-family: 'Inter', sans-serif;
        font-size: 1.2rem;
        color: rgba(255,255,255,0.9);
        font-weight: 300;
        letter-spacing: 2px;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
        border: 1px solid rgba(255,255,255,0.1);
        backdrop-filter: blur(10px);
    }
    
    .metric-value {
        font-family: 'Orbitron', monospace;
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: linear-gradient(45deg, #00f5ff, #0080ff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .metric-label {
        font-family: 'Inter', sans-serif;
        font-size: 0.9rem;
        opacity: 0.8;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    .section-header {
        font-family: 'Orbitron', monospace;
        font-size: 2rem;
        font-weight: 700;
        color: #2c3e50;
        margin: 2rem 0 1rem 0;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        border-left: 5px solid #667eea;
    }
    
    .feature-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        border: 1px solid rgba(255,255,255,0.2);
    }
    
    .prediction-zone {
        background: linear-gradient(135deg, #134e5e 0%, #71b280 100%);
        padding: 2rem;
        border-radius: 20px;
        color: white;
        margin: 2rem 0;
        box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        font-weight: 600;
        border: none;
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
    }
    
    .stSelectbox > div > div {
        background-color: rgba(255,255,255,0.1);
        border-radius: 10px;
        border: 1px solid rgba(255,255,255,0.2);
    }
    
    .plot-container {
        background: rgba(255,255,255,0.05);
        backdrop-filter: blur(10px);
        border-radius: 15px;
        padding: 1rem;
        border: 1px solid rgba(255,255,255,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Fonction de chargement des donn√©es avec cache
@st.cache_data
def load_data():
    """Charge et pr√©traite les donn√©es"""
    try:
        df = pd.read_csv('cleaned_dataset_1.csv')
        
        # Mapping des colonnes pour l'interpr√©tation
        feature_mapping = {
            'Age': '√Çge',
            'Gender': 'Genre', 
            'Weight (kg)': 'Poids (kg)',
            'Height (m)': 'Taille (m)',
            'Max_BPM': 'Fr√©quence cardiaque max',
            'Avg_BPM': 'Fr√©quence cardiaque moyenne',
            'Resting_BPM': 'Fr√©quence cardiaque repos',
            'Session_Duration (hours)': 'Dur√©e session (heures)',
            'Calories_Burned': 'Calories br√ªl√©es',
            'Workout_Type': 'Type d\'entra√Ænement',
            'Fat_Percentage': 'Pourcentage de graisse',
            'Water_Intake (liters)': 'Consommation d\'eau (litres)',
            'Workout_Frequency (days/week)': 'Fr√©quence d\'entra√Ænement (jours/semaine)',
            'Experience_Level': 'Niveau d\'exp√©rience',
            'BMI': 'IMC'
        }
        
        return df, feature_mapping
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es: {e}")
        return None, None

# Fonction pour cr√©er des graphiques personnalis√©s
def create_custom_plotly_figure(fig, title):
    """Applique un style personnalis√© aux figures Plotly"""
    fig.update_layout(
        title={
            'text': title,
            'x': 0.5,
            'font': {'family': 'Orbitron', 'size': 20, 'color': '#2c3e50'}
        },
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font={'family': 'Inter'},
        showlegend=True,
        legend=dict(
            bgcolor='rgba(255,255,255,0.1)',
            bordercolor='rgba(255,255,255,0.2)',
            borderwidth=1
        )
    )
    return fig

# Interface principale
def main():
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1 class="main-title">CONVEXOPT</h1>
        <p class="subtitle">Intelligence Artificielle & Optimisation Fitness</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Chargement des donn√©es
    df, feature_mapping = load_data()
    
    if df is None:
        st.error("üö® Impossible de charger les donn√©es. V√©rifiez que le fichier 'cleaned_dataset_1.csv' est pr√©sent.")
        return
    
    # Sidebar avec navigation
    st.sidebar.markdown("""
    <div style="text-align: center; padding: 1rem;">
        <h2 style="color: white; font-family: 'Orbitron';">üöÄ Navigation</h2>
    </div>
    """, unsafe_allow_html=True)
    
    page = st.sidebar.selectbox(
        "S√©lectionnez une section",
        ["üè† Vue d'ensemble", "üìä Analyse exploratoire", "üî¨ Visualisations avanc√©es", "üéØ Pr√©diction", "‚öôÔ∏è Optimisation", "üìà Monitoring"]
    )
    
    # M√©triques globales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{len(df):,}</div>
            <div class="metric-label">√âchantillons</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{len(df.columns)}</div>
            <div class="metric-label">Features</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        unique_workouts = df['Workout_Type'].nunique() if 'Workout_Type' in df.columns else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{unique_workouts}</div>
            <div class="metric-label">Types d'entra√Ænement</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        avg_calories = df['Calories_Burned'].mean() if 'Calories_Burned' in df.columns else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{avg_calories:.0f}</div>
            <div class="metric-label">Calories moy.</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Navigation des pages
    if page == "üè† Vue d'ensemble":
        show_overview(df, feature_mapping)
    elif page == "üìä Analyse exploratoire":
        show_exploratory_analysis(df, feature_mapping)
    elif page == "üî¨ Visualisations avanc√©es":
        show_advanced_visualizations(df, feature_mapping)
    elif page == "üéØ Pr√©diction":
        show_prediction_interface(df, feature_mapping)
    elif page == "‚öôÔ∏è Optimisation":
        show_optimization_section(df, feature_mapping)
    elif page == "üìà Monitoring":
        show_monitoring_section(df, feature_mapping)

def show_overview(df, feature_mapping):
    """Affiche la vue d'ensemble du dataset"""
    st.markdown('<h2 class="section-header">üè† Vue d\'ensemble du Dataset</h2>', unsafe_allow_html=True)
    
    # Onglets pour organiser l'information
    tab1, tab2, tab3, tab4 = st.tabs(["üìã Informations", "üîç Statistiques", "üìà Distribution", "üîó Corr√©lations"])
    
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="feature-box">
                <h3>üìä Structure des donn√©es</h3>
                <p>‚Ä¢ Dataset standardis√© et normalis√©</p>
                <p>‚Ä¢ Variables continues et cat√©gorielles</p>
                <p>‚Ä¢ Donn√©es fitness & biom√©triques</p>
                <p>‚Ä¢ Pr√™t pour l'optimisation ML</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Informations d√©taill√©es
            st.subheader("üîç D√©tails techniques")
            info_df = pd.DataFrame({
                'M√©trique': ['Lignes', 'Colonnes', 'Valeurs manquantes', 'Doublons', 'Taille m√©moire'],
                'Valeur': [
                    f"{len(df):,}",
                    f"{len(df.columns)}",
                    f"{df.isnull().sum().sum()}",
                    f"{df.duplicated().sum()}",
                    f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
                ]
            })
            st.dataframe(info_df, use_container_width=True)
        
        with col2:
            st.markdown("""
            <div class="feature-box">
                <h3>üéØ Objectifs du projet</h3>
                <p>‚Ä¢ Optimisation convexe avanc√©e</p>
                <p>‚Ä¢ Comparaison d'algorithmes (SGD, Adam...)</p>
                <p>‚Ä¢ Interpr√©tabilit√© des mod√®les</p>
                <p>‚Ä¢ Interface interactive temps r√©el</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Preview des donn√©es
            st.subheader("üëÄ Aper√ßu des donn√©es (5 premi√®res lignes)")
            st.dataframe(df.head(), use_container_width=True)
    
    with tab2:
        # Statistiques descriptives
        st.subheader("üìà Statistiques descriptives")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        stats_df = df[numeric_cols].describe().round(3)
        st.dataframe(stats_df, use_container_width=True)
        
        # Distribution des types de donn√©es
        col1, col2 = st.columns(2)
        with col1:
            dtype_counts = df.dtypes.value_counts()
            fig = px.pie(values=dtype_counts.values, names=[str(d) for d in dtype_counts.index], 
                        title="Distribution des types de donn√©es")

            fig = create_custom_plotly_figure(fig, "Distribution des types de donn√©es")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Visualisation des valeurs manquantes
            missing_data = df.isnull().sum().sort_values(ascending=False)
            if missing_data.sum() > 0:
                fig = px.bar(x=missing_data.index, y=missing_data.values, 
                           title="Valeurs manquantes par variable")
                fig = create_custom_plotly_figure(fig, "Valeurs manquantes par variable")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("‚úÖ Aucune valeur manquante d√©tect√©e!")
    
    with tab3:
        # Distribution des variables principales
        st.subheader("üìä Distributions des variables cl√©s")
        
        # S√©lection de variables √† visualiser
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        selected_vars = st.multiselect(
            "S√©lectionnez les variables √† analyser:",
            numeric_cols,
            default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols
        )
        
        if selected_vars:
            # Cr√©er des histogrammes
            n_cols = 2
            n_rows = (len(selected_vars) + 1) // 2
            
            fig = make_subplots(
                rows=n_rows, cols=n_cols,
                subplot_titles=selected_vars,
                specs=[[{"secondary_y": False}] * n_cols for _ in range(n_rows)]
            )
            
            for i, var in enumerate(selected_vars):
                row = (i // n_cols) + 1
                col = (i % n_cols) + 1
                
                fig.add_trace(
                    go.Histogram(x=df[var], name=var, showlegend=False),
                    row=row, col=col
                )
            
            fig.update_layout(height=300*n_rows, showlegend=False)
            fig = create_custom_plotly_figure(fig, "Distributions des variables s√©lectionn√©es")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        # Matrice de corr√©lation
        st.subheader("üîó Analyse des corr√©lations")
        
        numeric_df = df.select_dtypes(include=[np.number])
        if len(numeric_df.columns) > 1:
            corr_matrix = df.corr(numeric_only=True)

            # ‚ûï Conversion explicite
            corr_matrix = corr_matrix.astype(float)

            # ‚ûï Cr√©ation de la figure corrig√©e
            fig = px.imshow(
                corr_matrix.to_numpy(),
                x=corr_matrix.columns.astype(str),
                y=corr_matrix.index.astype(str),
                text_auto=True,
                aspect="auto",
                color_continuous_scale='RdBu_r',
                title="Matrice de corr√©lation des variables num√©riques"
            )


            fig = create_custom_plotly_figure(fig, "Matrice de corr√©lation")
            st.plotly_chart(fig, use_container_width=True)

            
            # Top corr√©lations
            st.subheader("üîù Corr√©lations les plus fortes")
            corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_pairs.append({
                        'Variable 1': corr_matrix.columns[i],
                        'Variable 2': corr_matrix.columns[j],
                        'Corr√©lation': corr_matrix.iloc[i, j]
                    })
            
            corr_df = pd.DataFrame(corr_pairs)
            corr_df = corr_df.reindex(corr_df['Corr√©lation'].abs().sort_values(ascending=False).index)
            st.dataframe(corr_df.head(10), use_container_width=True)

def show_exploratory_analysis(df, feature_mapping):
    """Section d'analyse exploratoire approfondie"""
    st.markdown('<h2 class="section-header">üìä Analyse Exploratoire Avanc√©e</h2>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üéØ Variables cibles", "üîç Segmentation", "üìà Tendances"])
    
    with tab1:
        # Analyse des variables potentiellement cibles
        st.subheader("üéØ Identification des variables cibles potentielles")
        
        target_candidates = ['Calories_Burned', 'BMI', 'Fat_Percentage', 'Avg_BPM']
        available_targets = [col for col in target_candidates if col in df.columns]
        
        if available_targets:
            selected_target = st.selectbox("S√©lectionnez une variable cible:", available_targets)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribution de la variable cible
                fig = px.histogram(df, x=selected_target, nbins=30, 
                                 title=f"Distribution de {selected_target}")
                fig = create_custom_plotly_figure(fig, f"Distribution de {selected_target}")
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Box plot par cat√©gorie si disponible
                if 'Experience_Level' in df.columns:
                    fig = px.box(df, y=selected_target, x='Experience_Level',
                               title=f"{selected_target} par niveau d'exp√©rience")
                    fig = create_custom_plotly_figure(fig, f"{selected_target} par niveau d'exp√©rience")
                    st.plotly_chart(fig, use_container_width=True)
            
            # Statistiques de la variable cible
            target_stats = df[selected_target].describe()
            st.subheader(f"üìä Statistiques pour {selected_target}")
            
            metric_cols = st.columns(5)
            metrics = ['mean', 'std', 'min', 'max', '50%']
            labels = ['Moyenne', '√âcart-type', 'Minimum', 'Maximum', 'M√©diane']
            
            for i, (metric, label) in enumerate(zip(metrics, labels)):
                with metric_cols[i]:
                    st.metric(label, f"{target_stats[metric]:.2f}")
    
    with tab2:
        # Analyse de segmentation
        st.subheader("üîç Segmentation des donn√©es")
        
        # S√©lection des variables de segmentation
        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if categorical_cols:
            segment_var = st.selectbox("Variable de segmentation:", categorical_cols)
            metric_var = st.selectbox("M√©trique √† analyser:", numeric_cols)
            
            # Analyse par segment
            segment_analysis = df.groupby(segment_var)[metric_var].agg(['count', 'mean', 'std', 'min', 'max']).round(2)
            st.dataframe(segment_analysis, use_container_width=True)
            
            # Visualisation
            fig = px.violin(df, x=segment_var, y=metric_var,
                          title=f"Distribution de {metric_var} par {segment_var}")
            fig = create_custom_plotly_figure(fig, f"Distribution de {metric_var} par {segment_var}")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        # Analyse des tendances
        st.subheader("üìà Analyse des tendances et patterns")
        
        # Scatter plot matrix pour explorer les relations
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        selected_features = st.multiselect(
            "S√©lectionnez les variables pour l'analyse crois√©e:",
            numeric_cols,
            default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols
        )
        
        if len(selected_features) >= 2:
            # Cr√©er un scatter plot matrix
            fig = px.scatter_matrix(df[selected_features])
            fig = create_custom_plotly_figure(fig, "Matrice de nuages de points")
            st.plotly_chart(fig, use_container_width=True)
            
            # Analyse PCA si assez de variables
            if len(selected_features) >= 3:
                st.subheader("üî¨ Analyse en Composantes Principales (PCA)")
                
                # Standardisation des donn√©es
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(df[selected_features].fillna(df[selected_features].mean()))
                
                # PCA
                pca = PCA()
                pca_result = pca.fit_transform(scaled_data)
                
                # Variance expliqu√©e
                explained_var = pca.explained_variance_ratio_
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Graphique de la variance expliqu√©e
                    fig = px.bar(x=range(1, len(explained_var)+1), 
                               y=explained_var,
                               title="Variance expliqu√©e par composante")
                    fig = create_custom_plotly_figure(fig, "Variance expliqu√©e par composante")
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Projection sur les 2 premi√®res composantes
                    pca_df = pd.DataFrame(pca_result[:, :2], columns=['PC1', 'PC2'])
                    fig = px.scatter(pca_df, x='PC1', y='PC2',
                                   title="Projection PCA (2 premi√®res composantes)")
                    fig = create_custom_plotly_figure(fig, "Projection PCA")
                    st.plotly_chart(fig, use_container_width=True)

def show_advanced_visualizations(df, feature_mapping):
    """Visualisations avanc√©es et interactives"""
    st.markdown('<h2 class="section-header">üî¨ Visualisations Avanc√©es</h2>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üåê 3D & Interactif", "üî• Heatmaps", "üìä Comparatifs"])
    
    with tab1:
        st.subheader("üåê Visualisations 3D et interactives")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) >= 3:
            col1, col2, col3 = st.columns(3)
            with col1:
                x_var = st.selectbox("Axe X:", numeric_cols, key="3d_x")
            with col2:
                y_var = st.selectbox("Axe Y:", numeric_cols, index=1, key="3d_y")
            with col3:
                z_var = st.selectbox("Axe Z:", numeric_cols, index=2, key="3d_z")
            
            # Graphique 3D scatter
            fig = px.scatter_3d(df, x=x_var, y=y_var, z=z_var,
                              title=f"Visualisation 3D: {x_var} vs {y_var} vs {z_var}")
            
            fig.update_layout(
                scene=dict(
                    bgcolor='rgba(0,0,0,0)',
                    xaxis=dict(backgroundcolor='rgba(0,0,0,0)'),
                    yaxis=dict(backgroundcolor='rgba(0,0,0,0)'),
                    zaxis=dict(backgroundcolor='rgba(0,0,0,0)')
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # t-SNE si le dataset n'est pas trop grand
            if len(df) <= 5000:
                st.subheader("üî¨ Visualisation t-SNE")
                
                # Pr√©paration des donn√©es pour t-SNE
                numeric_data = df[numeric_cols].fillna(df[numeric_cols].mean())
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(numeric_data)
                
                # t-SNE
                tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(df)//4))
                tsne_result = tsne.fit_transform(scaled_data[:1000])  # Limite pour la performance
                
                tsne_df = pd.DataFrame(tsne_result, columns=['t-SNE 1', 't-SNE 2'])
                fig = px.scatter(tsne_df, x='t-SNE 1', y='t-SNE 2',
                               title="Projection t-SNE des donn√©es")
                fig = create_custom_plotly_figure(fig, "Projection t-SNE")
                st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("üî• Heatmaps avanc√©es")
        
        # Heatmap de corr√©lation avec clustering
        numeric_df = df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) > 2:
            corr_matrix = numeric_df.corr()
            
            # Dendrogramme et clustering
            fig = px.imshow(corr_matrix, 
                          text_auto=True,
                          color_continuous_scale='RdBu_r',
                          title="Matrice de corr√©lation avec clustering")
            fig = create_custom_plotly_figure(fig, "Matrice de corr√©lation avec clustering")
            st.plotly_chart(fig, use_container_width=True)
            
            # Heatmap des statistiques par groupe
            if 'Experience_Level' in df.columns:
                st.subheader("üìä Heatmap des moyennes par groupe")
                
                group_stats = df.groupby('Experience_Level')[numeric_df.columns].mean()
                
                fig = px.imshow(group_stats.T,
                              text_auto=True,
                              aspect="auto",
                              title="Moyennes des variables par niveau d'exp√©rience")
                fig = create_custom_plotly_figure(fig, "Moyennes par niveau d'exp√©rience")
                st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("üìä Analyses comparatives")
        
        # Comparaison de distributions
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) >= 2:
            var1 = st.selectbox("Variable 1:", numeric_cols, key="comp_var1")
            var2 = st.selectbox("Variable 2:", numeric_cols, index=1, key="comp_var2")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Distributions superpos√©es
                fig = go.Figure()
                fig.add_trace(go.Histogram(x=df[var1], name=var1, opacity=0.7))
                fig.add_trace(go.Histogram(x=df[var2], name=var2, opacity=0.7))
                fig.update_layout(barmode='overlay', title=f"Comparaison des distributions: {var1} vs {var2}")
                fig = create_custom_plotly_figure(fig, f"Distributions: {var1} vs {var2}")
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Scatter plot avec r√©gression
                fig = px.scatter(df, x=var1, y=var2, trendline="ols",
                               title=f"Relation entre {var1} et {var2}")
                fig = create_custom_plotly_figure(fig, f"Relation: {var1} vs {var2}")
                st.plotly_chart(fig, use_container_width=True)
            
            # Comparaison statistique
            st.subheader("üìà Comparaison statistique")
            
            comparison_stats = pd.DataFrame({
                'Statistique': ['Moyenne', 'M√©diane', '√âcart-type', 'Min', 'Max', 'Asym√©trie', 'Aplatissement'],
                var1: [
                    df[var1].mean(),
                    df[var1].median(),
                    df[var1].std(),
                    df[var1].min(),
                    df[var1].max(),
                    df[var1].skew(),
                    df[var1].kurtosis()
                ],
                var2: [
                    df[var2].mean(),
                    df[var2].median(),
                    df[var2].std(),
                    df[var2].min(),
                    df[var2].max(),
                    df[var2].skew(),
                    df[var2].kurtosis()
                ]
            }).round(3)
            
            st.dataframe(comparison_stats, use_container_width=True)

def show_prediction_interface(df, feature_mapping):
    """Interface de pr√©diction interactive"""
    st.markdown('<h2 class="section-header">üéØ Interface de Pr√©diction</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="prediction-zone">
        <h3>üöÄ Zone de Pr√©diction Interactive</h3>
        <p>Cette section sera int√©gr√©e avec les mod√®les d√©velopp√©s par l'√©quipe.</p>
        <p>Fonctionnalit√©s pr√©vues:</p>
        <ul>
            <li>‚úÖ S√©lection de profils utilisateurs</li>
            <li>‚úÖ Pr√©dictions en temps r√©el</li>
            <li>‚úÖ Visualisation des r√©sultats</li>
            <li>‚úÖ Analyse de sensibilit√©</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üë§ Profil utilisateur", "üîÆ Pr√©diction", "üìä Analyse"])
    
    with tab1:
        st.subheader("üë§ Configuration du profil utilisateur")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Param√®tres utilisateur
            st.markdown("### üìù Informations personnelles")
            
            age = st.slider("√Çge", 18, 80, 30)
            gender = st.selectbox("Genre", ["Homme", "Femme"])
            weight = st.slider("Poids (kg)", 40, 150, 70)
            height = st.slider("Taille (cm)", 140, 220, 170)
            
            # Calcul automatique de l'IMC
            bmi = weight / ((height/100) ** 2)
            st.metric("IMC calcul√©", f"{bmi:.1f}")
            
        with col2:
            st.markdown("### üèãÔ∏è Param√®tres d'entra√Ænement")
            
            experience = st.selectbox("Niveau d'exp√©rience", 
                                    ["D√©butant", "Interm√©diaire", "Avanc√©", "Expert"])
            workout_type = st.selectbox("Type d'entra√Ænement pr√©f√©r√©", 
                                      ["Cardio", "Musculation", "HIIT", "Yoga", "Crossfit"])
            frequency = st.slider("Fr√©quence (jours/semaine)", 1, 7, 3)
            duration = st.slider("Dur√©e moyenne (heures)", 0.5, 3.0, 1.0, 0.5)
            
        # Affichage du profil cr√©√©
        st.subheader("üìã Profil utilisateur cr√©√©")
        
        user_profile = {
            "√Çge": age,
            "Genre": gender,
            "Poids": f"{weight} kg",
            "Taille": f"{height} cm",
            "IMC": f"{bmi:.1f}",
            "Exp√©rience": experience,
            "Type d'entra√Ænement": workout_type,
            "Fr√©quence": f"{frequency} jours/semaine",
            "Dur√©e": f"{duration} heures"
        }
        
        profile_df = pd.DataFrame(list(user_profile.items()), columns=['Param√®tre', 'Valeur'])
        st.dataframe(profile_df, use_container_width=True)
    
    with tab2:
        st.subheader("üîÆ Simulation de pr√©diction")
        
        # Simulation de pr√©diction (√† remplacer par le vrai mod√®le)
        if st.button("üöÄ Lancer la pr√©diction", type="primary"):
            
            # Simulation de calculs
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            import time
            
            for i in range(100):
                progress_bar.progress(i + 1)
                if i < 30:
                    status_text.text('üîÑ Pr√©paration des donn√©es...')
                elif i < 60:
                    status_text.text('üß† Calcul des pr√©dictions...')
                elif i < 90:
                    status_text.text('üìä Analyse des r√©sultats...')
                else:
                    status_text.text('‚úÖ Pr√©diction termin√©e!')
                time.sleep(0.02)
            
            # R√©sultats simul√©s
            col1, col2, col3 = st.columns(3)
            
            with col1:
                predicted_calories = np.random.randint(200, 800)
                st.metric("Calories pr√©dites", f"{predicted_calories} kcal", 
                         delta=f"+{np.random.randint(10, 50)} vs moyenne")
            
            with col2:
                predicted_performance = np.random.uniform(0.7, 0.95)
                st.metric("Score de performance", f"{predicted_performance:.2f}", 
                         delta=f"+{np.random.uniform(0.01, 0.1):.2f}")
            
            with col3:
                predicted_risk = np.random.uniform(0.1, 0.3)
                st.metric("Risque de blessure", f"{predicted_risk:.2f}", 
                         delta=f"-{np.random.uniform(0.01, 0.05):.2f}")
            
            # Graphique de pr√©diction
            st.subheader("üìà √âvolution pr√©dite")
            
            days = np.arange(1, 31)
            predicted_progress = np.cumsum(np.random.normal(2, 1, 30)) + 100
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=days, y=predicted_progress, 
                                   mode='lines+markers', name='Progression pr√©dite',
                                   line=dict(color='#667eea', width=3)))
            
            fig.update_layout(
                title='Progression fitness pr√©dite (30 jours)',
                xaxis_title='Jours',
                yaxis_title='Score de fitness',
                hovermode='x unified'
            )
            
            fig = create_custom_plotly_figure(fig, 'Progression fitness pr√©dite')
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("üìä Analyse de sensibilit√©")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üîç Analyse d'impact des variables</h4>
            <p>Cette section analysera l'impact de chaque variable sur les pr√©dictions.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Simulation d'analyse de sensibilit√©
        variables = ['√Çge', 'Poids', 'Fr√©quence', 'Dur√©e', 'Exp√©rience']
        importance = np.random.dirichlet(np.ones(len(variables))) * 100
        
        # Graphique d'importance des variables
        fig = px.bar(x=variables, y=importance, 
                    title="Importance des variables sur la pr√©diction")
        fig = create_custom_plotly_figure(fig, "Importance des variables")
        st.plotly_chart(fig, use_container_width=True)
        
        # Analyse SHAP simul√©e
        st.subheader("üéØ Analyse SHAP (simul√©e)")
        
        shap_values = np.random.normal(0, 1, len(variables))
        colors = ['red' if x < 0 else 'green' for x in shap_values]
        
        fig = go.Figure(go.Bar(
            x=shap_values,
            y=variables,
            orientation='h',
            marker=dict(color=colors)
        ))
        
        fig.update_layout(
            title='Valeurs SHAP - Impact sur la pr√©diction',
            xaxis_title='Impact SHAP',
            yaxis_title='Variables'
        )
        
        fig = create_custom_plotly_figure(fig, 'Valeurs SHAP')
        st.plotly_chart(fig, use_container_width=True)

def show_optimization_section(df, feature_mapping):
    """Section d√©di√©e √† l'optimisation et aux algorithmes"""
    st.markdown('<h2 class="section-header">‚öôÔ∏è Optimisation & Algorithmes</h2>', unsafe_allow_html=True)
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìê Gradient Descent", "üöÄ Optimizers", "üìä Convergence", "üî¨ Exp√©rimentations"])
    
    with tab1:
        st.subheader("üìê Visualisation du Gradient Descent")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üéØ Simulation interactive du Gradient Descent</h4>
            <p>Cette section int√©grera les impl√©mentations manuelles de l'√©quipe.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Param√®tres de simulation
        col1, col2 = st.columns(2)
        
        with col1:
            learning_rate = st.slider("Learning Rate", 0.001, 0.1, 0.01, 0.001)
            n_iterations = st.slider("Nombre d'it√©rations", 10, 100, 50)
            
        with col2:
            optimizer_type = st.selectbox("Type d'optimiseur", 
                                        ["SGD", "Batch GD", "Mini-batch GD", "Adam", "RMSprop"])
            batch_size = st.slider("Taille du batch", 1, 100, 32)
        
        # Simulation de la descente de gradient
        if st.button("üöÄ Simuler la descente de gradient"):
            
            # G√©n√©ration de donn√©es simul√©es pour la d√©monstration
            np.random.seed(42)
            x = np.linspace(-10, 10, 100)
            y = x**2 + 2*x + 1 + np.random.normal(0, 5, 100)  # Fonction quadratique avec bruit
            
            # Simulation de l'√©volution des param√®tres
            iterations = np.arange(n_iterations)
            loss_history = []
            
            # Simulation de la perte qui diminue
            initial_loss = 1000
            for i in iterations:
                if optimizer_type == "Adam":
                    # Adam converge plus rapidement
                    loss = initial_loss * np.exp(-0.15 * i) + np.random.normal(0, 5)
                elif optimizer_type == "SGD":
                    # SGD plus chaotique
                    loss = initial_loss * np.exp(-0.05 * i) + np.random.normal(0, 20)
                else:
                    # Autres optimiseurs
                    loss = initial_loss * np.exp(-0.1 * i) + np.random.normal(0, 10)
                
                loss_history.append(max(loss, 0))
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Courbe de perte
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=iterations, y=loss_history, 
                                       mode='lines+markers', name='Loss',
                                       line=dict(color='#e74c3c', width=2)))
                
                fig.update_layout(
                    title=f'√âvolution de la perte - {optimizer_type}',
                    xaxis_title='It√©rations',
                    yaxis_title='Loss',
                    yaxis_type="log"
                )
                
                fig = create_custom_plotly_figure(fig, f'Loss - {optimizer_type}')
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Trajectoire dans l'espace des param√®tres (simulation 2D)
                theta1 = np.random.normal(0, 1, n_iterations).cumsum() * 0.1
                theta2 = np.random.normal(0, 1, n_iterations).cumsum() * 0.1
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=theta1, y=theta2, 
                                       mode='lines+markers', name='Trajectoire',
                                       line=dict(color='#3498db', width=2)))
                
                fig.add_trace(go.Scatter(x=[theta1[0]], y=[theta2[0]], 
                                       mode='markers', name='D√©but',
                                       marker=dict(color='green', size=10)))
                
                fig.add_trace(go.Scatter(x=[theta1[-1]], y=[theta2[-1]], 
                                       mode='markers', name='Fin',
                                       marker=dict(color='red', size=10)))
                
                fig.update_layout(
                    title='Trajectoire dans l\'espace des param√®tres',
                    xaxis_title='Œ∏‚ÇÅ',
                    yaxis_title='Œ∏‚ÇÇ'
                )
                
                fig = create_custom_plotly_figure(fig, 'Trajectoire des param√®tres')
                st.plotly_chart(fig, use_container_width=True)
            
            # M√©triques de convergence
            st.subheader("üìä M√©triques de convergence")
            
            metrics_col1, metrics_col2, metrics_col3, metrics_col4 = st.columns(4)
            
            with metrics_col1:
                st.metric("Loss finale", f"{loss_history[-1]:.2f}")
            
            with metrics_col2:
                st.metric("R√©duction de loss", f"{((loss_history[0] - loss_history[-1])/loss_history[0]*100):.1f}%")
            
            with metrics_col3:
                convergence_iter = next((i for i, loss in enumerate(loss_history) if loss < loss_history[0] * 0.1), n_iterations)
                st.metric("Convergence √†", f"{convergence_iter} iter")
            
            with metrics_col4:
                st.metric("Learning Rate", f"{learning_rate}")
    
    with tab2:
        st.subheader("üöÄ Comparaison des optimiseurs")
        
        st.markdown("""
        <div class="feature-box">
            <h4>‚ö° Analyse comparative des algorithmes d'optimisation</h4>
            <p>Comparaison d√©taill√©e des performances de SGD, Adam, RMSprop, etc.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Simulation comparative
        optimizers = ['SGD', 'Adam', 'RMSprop', 'AdaGrad', 'Momentum']
        
        if st.button("üìä Comparer les optimiseurs"):
            fig = go.Figure()
            
            iterations = np.arange(100)
            
            # Simulation de diff√©rentes courbes de convergence
            for i, opt in enumerate(optimizers):
                if opt == 'Adam':
                    loss = 1000 * np.exp(-0.15 * iterations) + np.random.normal(0, 2, 100)
                elif opt == 'SGD':
                    loss = 1000 * np.exp(-0.03 * iterations) + np.random.normal(0, 15, 100)
                elif opt == 'RMSprop':
                    loss = 1000 * np.exp(-0.1 * iterations) + np.random.normal(0, 5, 100)
                elif opt == 'AdaGrad':
                    loss = 1000 * np.exp(-0.08 * iterations) + np.random.normal(0, 8, 100)
                else:  # Momentum
                    loss = 1000 * np.exp(-0.12 * iterations) + np.random.normal(0, 6, 100)
                
                loss = np.maximum(loss, 1)  # √âviter les valeurs n√©gatives
                
                fig.add_trace(go.Scatter(x=iterations, y=loss, 
                                       mode='lines', name=opt,
                                       line=dict(width=2)))
            
            fig.update_layout(
                title='Comparaison des optimiseurs',
                xaxis_title='It√©rations',
                yaxis_title='Loss',
                yaxis_type="log"
            )
            
            fig = create_custom_plotly_figure(fig, 'Comparaison optimiseurs')
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau de comparaison
            st.subheader("üìà Tableau comparatif")
            
            comparison_data = {
                'Optimiseur': optimizers,
                'Vitesse de convergence': ['Lente', 'Rapide', 'Moyenne', 'Moyenne', 'Rapide'],
                'Stabilit√©': ['Haute', 'Moyenne', 'Haute', 'Faible', 'Moyenne'],
                'M√©moire': ['Faible', 'Moyenne', 'Moyenne', 'Moyenne', 'Faible'],
                'Recommandation': ['üü° Baseline', 'üü¢ Recommand√©', 'üü¢ Bon choix', 'üî¥ Attention', 'üü° Classique']
            }
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True)
    
    with tab3:
        st.subheader("üìä Analyse de convergence")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üéØ √âtude de la convergence</h4>
            <p>Analyse approfondie des crit√®res de convergence et de la stabilit√©.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Param√®tres d'analyse
        col1, col2 = st.columns(2)
        
        with col1:
            conv_threshold = st.slider("Seuil de convergence", 0.001, 0.1, 0.01)
            window_size = st.slider("Fen√™tre d'analyse", 5, 50, 10)
        
        with col2:
            noise_level = st.slider("Niveau de bruit", 0.0, 0.5, 0.1)
            decay_rate = st.slider("Taux de d√©croissance", 0.01, 0.2, 0.05)
        
        # G√©n√©ration de donn√©es de convergence
        n_points = 200
        x = np.arange(n_points)
        
        # Fonction de perte avec diff√©rents comportements
        base_loss = 100 * np.exp(-decay_rate * x)
        noise = np.random.normal(0, noise_level * base_loss)
        loss_with_noise = base_loss + noise
        
        # D√©tection de convergence
        converged_points = []
        for i in range(window_size, len(loss_with_noise)):
            window = loss_with_noise[i-window_size:i]
            if np.std(window) < conv_threshold:
                converged_points.append(i)
        
        # Graphique de convergence
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(x=x, y=loss_with_noise, 
                               mode='lines', name='Loss avec bruit',
                               line=dict(color='#3498db', width=1)))
        
        fig.add_trace(go.Scatter(x=x, y=base_loss, 
                               mode='lines', name='Loss th√©orique',
                               line=dict(color='#e74c3c', width=2, dash='dash')))
        
        if converged_points:
            convergence_point = converged_points[0]
            fig.add_vline(x=convergence_point, line_dash="dot", line_color="green",
                         annotation_text=f"Convergence √† {convergence_point}")
        
        fig.update_layout(
            title='Analyse de la convergence',
            xaxis_title='It√©rations',
            yaxis_title='Loss',
            yaxis_type="log"
        )
        
        fig = create_custom_plotly_figure(fig, 'Analyse de convergence')
        st.plotly_chart(fig, use_container_width=True)
        
        # M√©triques de convergence
        if converged_points:
            conv_metrics_col1, conv_metrics_col2, conv_metrics_col3 = st.columns(3)
            
            with conv_metrics_col1:
                st.metric("Point de convergence", f"{converged_points[0]} iterations")
            
            with conv_metrics_col2:
                final_loss = loss_with_noise[converged_points[0]]
                st.metric("Loss √† la convergence", f"{final_loss:.4f}")
            
            with conv_metrics_col3:
                stability = np.std(loss_with_noise[converged_points[0]:])
                st.metric("Stabilit√© post-convergence", f"{stability:.4f}")
    
    with tab4:
        st.subheader("üî¨ Exp√©rimentations")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üß™ Laboratoire d'exp√©rimentation</h4>
            <p>Zone d'exp√©rimentation pour tester diff√©rents hyperparam√®tres.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Configuration d'exp√©rience
        st.subheader("‚öôÔ∏è Configuration de l'exp√©rience")
        
        exp_col1, exp_col2, exp_col3 = st.columns(3)
        
        with exp_col1:
            lr_range = st.slider("Plage de Learning Rate", 0.001, 0.1, (0.01, 0.05), 0.001)
            
        with exp_col2:
            batch_sizes = st.multiselect("Tailles de batch √† tester", 
                                       [8, 16, 32, 64, 128], 
                                       default=[16, 32, 64])
        
        with exp_col3:
            n_experiments = st.slider("Nombre d'exp√©riences", 3, 10, 5)
        
        # Lancement des exp√©riences
        if st.button("üöÄ Lancer les exp√©riences"):
            
            # Simulation de grille d'exp√©riences
            results = []
            
            learning_rates = np.linspace(lr_range[0], lr_range[1], n_experiments)
            
            for lr in learning_rates:
                for batch_size in batch_sizes:
                    # Simulation de r√©sultats
                    final_loss = np.random.uniform(0.1, 1.0) / lr * (batch_size / 32)
                    convergence_time = np.random.randint(50, 200)
                    stability = np.random.uniform(0.01, 0.1)
                    
                    results.append({
                        'Learning Rate': lr,
                        'Batch Size': batch_size,
                        'Final Loss': final_loss,
                        'Convergence Time': convergence_time,
                        'Stability': stability,
                        'Score': 1 / (final_loss * convergence_time * stability)
                    })
            
            results_df = pd.DataFrame(results)
            
            # Affichage des r√©sultats
            st.subheader("üìä R√©sultats des exp√©riences")
            st.dataframe(results_df.round(4), use_container_width=True)
            
            # Heatmap des r√©sultats
            col1, col2 = st.columns(2)
            
            with col1:
                # Heatmap Learning Rate vs Batch Size pour Final Loss
                pivot_loss = results_df.pivot_table(values='Final Loss', 
                                                   index='Learning Rate', 
                                                   columns='Batch Size', 
                                                   aggfunc='mean')
                
                fig = px.imshow(pivot_loss, 
                              title="Final Loss par LR et Batch Size",
                              color_continuous_scale='RdYlBu_r')
                fig = create_custom_plotly_figure(fig, "Final Loss Heatmap")
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Heatmap pour Convergence Time
                pivot_time = results_df.pivot_table(values='Convergence Time', 
                                                   index='Learning Rate', 
                                                   columns='Batch Size', 
                                                   aggfunc='mean')
                
                fig = px.imshow(pivot_time, 
                              title="Temps de convergence par LR et Batch Size",
                              color_continuous_scale='RdYlGn_r')
                fig = create_custom_plotly_figure(fig, "Convergence Time Heatmap")
                st.plotly_chart(fig, use_container_width=True)
            
            # Recommandations automatiques
            best_config = results_df.loc[results_df['Score'].idxmax()]
            
            st.subheader("üèÜ Meilleure configuration trouv√©e")
            
            best_col1, best_col2, best_col3, best_col4 = st.columns(4)
            
            with best_col1:
                st.metric("Learning Rate", f"{best_config['Learning Rate']:.4f}")
            
            with best_col2:
                st.metric("Batch Size", f"{int(best_config['Batch Size'])}")
            
            with best_col3:
                st.metric("Final Loss", f"{best_config['Final Loss']:.4f}")
            
            with best_col4:
                st.metric("Score", f"{best_config['Score']:.2f}")

def show_monitoring_section(df, feature_mapping):
    """Section de monitoring et m√©triques temps r√©el"""
    st.markdown('<h2 class="section-header">üìà Monitoring & M√©triques</h2>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üìä Dashboard", "üîç Diagnostics", "üìù Logs"])
    
    with tab1:
        st.subheader("üìä Dashboard de monitoring")
        
        # M√©triques temps r√©el simul√©es
        st.markdown("### üöÄ M√©triques temps r√©el")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            accuracy = np.random.uniform(0.85, 0.95)
            st.metric("Accuracy", f"{accuracy:.3f}", delta=f"{np.random.uniform(-0.005, 0.005):.3f}")
        
        with col2:
            loss = np.random.uniform(0.1, 0.3)
            st.metric("Loss", f"{loss:.3f}", delta=f"{np.random.uniform(-0.01, 0.01):.3f}")
        
        with col3:
            f1_score = np.random.uniform(0.80, 0.90)
            st.metric("F1-Score", f"{f1_score:.3f}", delta=f"{np.random.uniform(-0.01, 0.01):.3f}")
        
        with col4:
            precision = np.random.uniform(0.82, 0.92)
            st.metric("Precision", f"{precision:.3f}", delta=f"{np.random.uniform(-0.01, 0.01):.3f}")
        
        with col5:
            recall = np.random.uniform(0.78, 0.88)
            st.metric("Recall", f"{recall:.3f}", delta=f"{np.random.uniform(-0.01, 0.01):.3f}")
        
        # Graphiques de monitoring
        st.markdown("### üìà √âvolution des m√©triques")
        
        # G√©n√©ration de donn√©es temporelles
        time_points = pd.date_range(start='2024-01-01', periods=30, freq='D')
        
        # Simulation de m√©triques qui √©voluent dans le temps
        accuracy_history = 0.7 + 0.2 * np.random.random(30).cumsum() / 30 + np.random.normal(0, 0.01, 30)
        loss_history = 1.0 * np.exp(-np.arange(30) / 10) + np.random.normal(0, 0.02, 30)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # √âvolution de l'accuracy
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=time_points, y=accuracy_history,
                                   mode='lines+markers', name='Accuracy',
                                   line=dict(color='#2ecc71', width=3)))
            
            fig.update_layout(
                title='√âvolution de l\'Accuracy',
                xaxis_title='Date',
                yaxis_title='Accuracy',
                yaxis=dict(range=[0.7, 1.0])
            )
            
            fig = create_custom_plotly_figure(fig, '√âvolution Accuracy')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # √âvolution de la loss
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=time_points, y=loss_history,
                                   mode='lines+markers', name='Loss',
                                   line=dict(color='#e74c3c', width=3)))
            
            fig.update_layout(
                title='√âvolution de la Loss',
                xaxis_title='Date',
                yaxis_title='Loss'
            )
            
            fig = create_custom_plotly_figure(fig, '√âvolution Loss')
            st.plotly_chart(fig, use_container_width=True)
        
        # Heatmap de performance par heure
        st.markdown("### üïê Performance par heure de la journ√©e")
        
        hours = np.arange(24)
        days = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
        
        # Simulation de donn√©es de performance par heure et jour
        performance_matrix = np.random.uniform(0.8, 0.95, (7, 24))
        
        fig = px.imshow(performance_matrix,
                       x=hours, y=days,
                       title="Heatmap de performance (Accuracy par heure)",
                       color_continuous_scale='RdYlGn')
        
        fig.update_layout(
            xaxis_title='Heure',
            yaxis_title='Jour de la semaine'
        )
        
        fig = create_custom_plotly_figure(fig, 'Performance Heatmap')
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("üîç Diagnostics avanc√©s")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üè• √âtat de sant√© du mod√®le</h4>
            <p>Surveillance automatique des anomalies et de la d√©rive des donn√©es.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Indicateurs de sant√©
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### üéØ Stabilit√© du mod√®le")
            
            stability_score = np.random.uniform(0.85, 0.98)
            stability_color = "green" if stability_score > 0.9 else "orange" if stability_score > 0.8 else "red"
            
            st.markdown(f"""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #2c3e50, #34495e); border-radius: 10px; color: white;">
                <h2 style="color: {stability_color}; margin: 0;">{stability_score:.2f}</h2>
                <p style="margin: 0;">Score de stabilit√©</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("#### üìä D√©rive des donn√©es")
            
            drift_score = np.random.uniform(0.05, 0.25)
            drift_color = "red" if drift_score > 0.2 else "orange" if drift_score > 0.1 else "green"
            
            st.markdown(f"""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #2c3e50, #34495e); border-radius: 10px; color: white;">
                <h2 style="color: {drift_color}; margin: 0;">{drift_score:.3f}</h2>
                <p style="margin: 0;">Indice de d√©rive</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("#### ‚ö° Performance syst√®me")
            
            system_health = np.random.uniform(0.90, 0.99)
            system_color = "green" if system_health > 0.95 else "orange" if system_health > 0.9 else "red"
            
            st.markdown(f"""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #2c3e50, #34495e); border-radius: 10px; color: white;">
                <h2 style="color: {system_color}; margin: 0;">{system_health:.2f}</h2>
                <p style="margin: 0;">Sant√© syst√®me</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Distribution des erreurs
        st.markdown("### üìà Analyse des erreurs")
        
        # Simulation d'erreurs
        n_samples = 1000
        errors = np.random.normal(0, 0.1, n_samples)
        predictions = np.random.uniform(0, 1, n_samples)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribution des erreurs
            fig = px.histogram(x=errors, nbins=50, title="Distribution des erreurs de pr√©diction")
            fig = create_custom_plotly_figure(fig, "Distribution des erreurs")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Erreurs vs pr√©dictions
            fig = px.scatter(x=predictions, y=errors, 
                           title="Erreurs vs Pr√©dictions",
                           trendline="ols")
            fig = create_custom_plotly_figure(fig, "Erreurs vs Pr√©dictions")
            st.plotly_chart(fig, use_container_width=True)
        
        # Alertes et recommandations
        st.markdown("### üö® Alertes et recommandations")
        
        # Simulation d'alertes
        alerts = []
        
        if drift_score > 0.15:
            alerts.append("‚ö†Ô∏è D√©rive des donn√©es d√©tect√©e - Consid√©rer un r√©entra√Ænement")
        
        if stability_score < 0.9:
            alerts.append("üî¥ Instabilit√© du mod√®le - V√©rifier les hyperparam√®tres")
        
        if system_health < 0.95:
            alerts.append("‚ö° Performance syst√®me d√©grad√©e - Optimisation recommand√©e")
        
        if not alerts:
            st.success("‚úÖ Tous les indicateurs sont dans les normes")
        else:
            for alert in alerts:
                st.warning(alert)
        
        # Recommandations automatiques
        st.markdown("### üí° Recommandations automatiques")
        
        recommendations = [
            "üîß Ajuster le learning rate pour am√©liorer la convergence",
            "üìä Augmenter la taille du dataset d'entra√Ænement",
            "üéØ Impl√©menter une validation crois√©e stratifi√©e",
            "‚öôÔ∏è Optimiser les hyperparam√®tres avec Bayesian Optimization",
            "üîÑ Mettre en place un pipeline de r√©entra√Ænement automatique"
        ]
        
        selected_recommendations = np.random.choice(recommendations, 3, replace=False)
        
        for i, rec in enumerate(selected_recommendations, 1):
            st.info(f"{i}. {rec}")
    
    with tab3:
        st.subheader("üìù Logs et historique")
        
        st.markdown("""
        <div class="feature-box">
            <h4>üìã Journal d'activit√© du syst√®me</h4>
            <p>Suivi d√©taill√© des √©v√©nements et des performances.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Simulation de logs
        log_entries = []
        log_levels = ['INFO', 'WARNING', 'ERROR', 'DEBUG']
        log_messages = [
            "Mod√®le charg√© avec succ√®s",
            "Pr√©diction effectu√©e pour utilisateur ID 12345",
            "Mise √† jour des poids du mod√®le",
            "Sauvegarde automatique effectu√©e",
            "D√©tection d'anomalie dans les donn√©es d'entr√©e",
            "Optimisation des hyperparam√®tres termin√©e",
            "√âvaluation des m√©triques compl√©t√©e",
            "Nettoyage des donn√©es temporaires",
            "Nouveau batch de donn√©es trait√©",
            "Validation crois√©e lanc√©e"
        ]
        
        # G√©n√©ration de logs simul√©s
        current_time = pd.Timestamp.now()
        
        for i in range(50):
            timestamp = current_time - pd.Timedelta(minutes=np.random.randint(1, 1440))  # Derni√®res 24h
            level = np.random.choice(log_levels, p=[0.6, 0.25, 0.1, 0.05])  # Distribution r√©aliste
            message = np.random.choice(log_messages)
            
            log_entries.append({
                'Timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                'Level': level,
                'Message': message,
                'Duration': f"{np.random.randint(10, 5000)}ms"
            })
        
        # Trier par timestamp d√©croissant
        log_df = pd.DataFrame(log_entries).sort_values('Timestamp', ascending=False)
        
        # Filtres pour les logs
        col1, col2, col3 = st.columns(3)
        
        with col1:
            level_filter = st.multiselect("Filtrer par niveau:", 
                                        log_levels, 
                                        default=log_levels)
        
        with col2:
            hours_back = st.slider("Derni√®res X heures:", 1, 24, 6)
        
        with col3:
            search_term = st.text_input("Rechercher dans les logs:")
        
        # Application des filtres
        filtered_logs = log_df[log_df['Level'].isin(level_filter)]
        
        if search_term:
            filtered_logs = filtered_logs[filtered_logs['Message'].str.contains(search_term, case=False)]
        
        # Affichage des logs avec style conditionnel
        st.markdown("### üìä Logs r√©cents")
        
        # Statistiques des logs
        stats_col1, stats_col2, stats_col3, stats_col4 = st.columns(4)
        
        with stats_col1:
            st.metric("Total logs", len(filtered_logs))
        
        with stats_col2:
            error_count = len(filtered_logs[filtered_logs['Level'] == 'ERROR'])
            st.metric("Erreurs", error_count, delta=-np.random.randint(0, 3))
        
        with stats_col3:
            warning_count = len(filtered_logs[filtered_logs['Level'] == 'WARNING'])
            st.metric("Avertissements", warning_count, delta=-np.random.randint(0, 5))
        
        with stats_col4:
            avg_duration = filtered_logs['Duration'].str.replace('ms', '').astype(float).mean()
            st.metric("Dur√©e moyenne", f"{avg_duration:.0f}ms")
        
        # Tableau des logs avec formatage conditionnel
        def color_logs(row):
            if row['Level'] == 'ERROR':
                return ['background-color: #ffebee'] * len(row)
            elif row['Level'] == 'WARNING':
                return ['background-color: #fff3e0'] * len(row)
            elif row['Level'] == 'INFO':
                return ['background-color: #e8f5e8'] * len(row)
            else:  # DEBUG
                return ['background-color: #f3e5f5'] * len(row)
        
        # Affichage du tableau
        st.dataframe(
            filtered_logs.head(20).style.apply(color_logs, axis=1),
            use_container_width=True,
            height=400
        )
        
        # Graphique de distribution des logs par niveau
        st.markdown("### üìä Distribution des logs par niveau")
        
        level_counts = filtered_logs['Level'].value_counts()
        
        fig = px.pie(values=level_counts.values, 
                    names=level_counts.index,
                    title="R√©partition des logs par niveau")
        
        fig = create_custom_plotly_figure(fig, "Distribution des logs")
        st.plotly_chart(fig, use_container_width=True)
        
        # Export des logs
        if st.button("üì• Exporter les logs"):
            csv = filtered_logs.to_csv(index=False)
            st.download_button(
                label="üíæ T√©l√©charger les logs (CSV)",
                data=csv,
                file_name=f"logs_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

# Footer avec informations sur l'√©quipe
def show_footer():
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; margin-top: 3rem;">
        <h3 style="font-family: 'Orbitron', monospace; margin-bottom: 1rem;">üöÄ ConvexOpt Team</h3>
        <p style="font-family: 'Inter', sans-serif; margin-bottom: 0.5rem;">
            <strong>Projet d'Optimisation Convexe & Machine Learning</strong>
        </p>
        <p style="font-family: 'Inter', sans-serif; font-size: 0.9rem; opacity: 0.9;">
            üî¨ Analyse th√©orique ‚Ä¢ üíª Impl√©mentation pratique ‚Ä¢ üìä Visualisations interactives ‚Ä¢ üéØ Interface utilisateur
        </p>
        <div style="margin-top: 1rem; font-size: 0.8rem; opacity: 0.8;">
            D√©velopp√© avec ‚ù§Ô∏è en Python | Streamlit | Plotly | Scikit-learn
        </div>
    </div>
    """, unsafe_allow_html=True)

# Sidebar avec informations additionnelles
def show_sidebar_info():
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style="background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); padding: 1rem; border-radius: 10px; color: white; margin-bottom: 1rem;">
        <h4 style="margin-top: 0; font-family: 'Orbitron';">‚ÑπÔ∏è Info Projet</h4>
        <p style="font-size: 0.8rem; margin-bottom: 0.5rem;"><strong>Dataset:</strong> Fitness & Biom√©trie</p>
        <p style="font-size: 0.8rem; margin-bottom: 0.5rem;"><strong>Algorithmes:</strong> SGD, Adam, RMSprop</p>
        <p style="font-size: 0.8rem; margin-bottom: 0.5rem;"><strong>Objectif:</strong> Optimisation convexe</p>
        <p style="font-size: 0.8rem; margin-bottom: 0;"><strong>Interface:</strong> Temps r√©el</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Indicateurs temps r√©el
    st.sidebar.markdown("""
    <div style="background: linear-gradient(135deg, #134e5e 0%, #71b280 100%); padding: 1rem; border-radius: 10px; color: white;">
        <h4 style="margin-top: 0; font-family: 'Orbitron';">üìä Status</h4>
        <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
            <span style="font-size: 0.8rem;">Syst√®me:</span>
            <span style="color: #2ecc71;">üü¢ Actif</span>
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
            <span style="font-size: 0.8rem;">Mod√®les:</span>
            <span style="color: #f39c12;">üü° En attente</span>
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 0;">
            <span style="font-size: 0.8rem;">API:</span>
            <span style="color: #2ecc71;">üü¢ Pr√™t</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Raccourcis rapides
    st.sidebar.markdown("### üöÄ Raccourcis")
    
    if st.sidebar.button("üîÑ Actualiser les donn√©es"):
        st.rerun()
    
    if st.sidebar.button("üìä Vue d'ensemble rapide"):
        st.session_state.quick_overview = True
    
    if st.sidebar.button("üéØ Test pr√©diction"):
        st.session_state.quick_prediction = True
    
    # Configuration avanc√©e
    with st.sidebar.expander("‚öôÔ∏è Configuration avanc√©e"):
        theme = st.selectbox("Th√®me:", ["Sombre", "Clair", "Auto"])
        auto_refresh = st.checkbox("Actualisation automatique")
        show_debug = st.checkbox("Mode debug")
        
        if show_debug:
            st.write("üîß Mode debug activ√©")
            st.write(f"Session state: {len(st.session_state)} items")

# Point d'entr√©e principal
if __name__ == "__main__":
    # Initialisation des √©tats de session
    if 'quick_overview' not in st.session_state:
        st.session_state.quick_overview = False
    if 'quick_prediction' not in st.session_state:
        st.session_state.quick_prediction = False
    
    # Affichage de la sidebar
    show_sidebar_info()
    
    # Application principale
    main()
    
    # Footer
    show_footer()
    
    # Actions rapides si d√©clench√©es
    if st.session_state.quick_overview:
        st.balloons()
        st.success("üéâ Vue d'ensemble mise √† jour!")
        st.session_state.quick_overview = False
    
    if st.session_state.quick_prediction:
        st.success("üéØ Interface de pr√©diction pr√™te!")
        st.session_state.quick_prediction = False